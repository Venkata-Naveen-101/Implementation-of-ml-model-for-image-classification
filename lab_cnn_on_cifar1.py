# -*- coding: utf-8 -*-
"""Lab_CNN on Cifar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GHrux4sjkN66EXQ9SUAxcFYuhk8QS7WX
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

tf.__version__

np.__version__

mlt.__version__

"""**Check for GPU**"""

physical_devices = tf.config.list_physical_devices('GPU')
print("Num GPUs Available: ", len(physical_devices))

from keras.datasets import cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

cifar10_classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']
print('Example training images and their labels: '+str([x[0] for x in y_train[0:10]]))
print('Corresponding classes for the labels: '+str([cifar10_classes[x[0]] for x in y_train[0:10]]))

fig, axarr = plt.subplots(1,10)
fig.set_size_inches(20,6)
for i in range(10):
  image = x_train[i]
  axarr[i].imshow(image)
plt.show()

x_train.shape,y_train.shape,x_test.shape,y_test.shape

"""**Preparing the dataset**"""

x_train = x_train /255.0
x_test = x_test /255.0

"""**MLP Network**"""

from tensorflow import keras
from keras.layers import Dense, Flatten

ann = keras.models.Sequential()
ann.add(Flatten(input_shape=(32,32,3)))
ann.add(Dense(2048, activation='relu'))
ann.add(Dense(10, activation='softmax'))

ann.summary()

ann.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')

history =ann.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

from tensorflow import keras
from keras.layers import Conv2D, MaxPooling2D,Dropout, Flatten, Dense

cnn = keras.Sequential()
cnn.add(Conv2D(filters=32, kernel_size=(3,3),strides=(1,1),padding='same', activation='relu', input_shape=(32,32,3)))
cnn.add(MaxPooling2D(pool_size=(2,2)))
cnn.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),padding='same',activation='relu'))
cnn.add(MaxPooling2D(pool_size=(2,2)))
cnn.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),padding='same',activation='relu'))
cnn.add(MaxPooling2D(pool_size=(2,2)))
cnn.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),padding='same',activation='relu'))
cnn.add(MaxPooling2D(pool_size=(2,2)))
cnn.add(Flatten())
cnn.add(Dense(64, activation='relu'))
cnn.add(Dropout(0.3))
cnn.add(Dense(10, activation='softmax'))

cnn.summary()

cnn.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')
history =cnn.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

def plotlosses(history):
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('Model Loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['train', 'validation'], loc='upper right')
  plt.show()

plotlosses(history)

def plotaccuracy(history):
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('Model Accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['train', 'validation'], loc='upper left')
  plt.show()

plotaccuracy(history)

score = cnn.evaluate(x_test, y_test)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

from keras.models import load_model
cnn.save('cnn_model.h5')

! pip install streamlit -q

!wget -q -O - ipv4.icanhazip.com

! streamlit run app.py & npx localtunnel --port 8501

